{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytesseract pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"C:\\\\Users\\\\LCSS\\\\Desktop\\\\DS sip\\\\Capture.PNG\"\n",
    "image = Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(image)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = pytesseract.image_to_string(image)\n",
    "image_name = \"image.jpg\"\n",
    "timestamp = \"2023-06-24\"\n",
    "\n",
    "output_file = \"output.csv\"\n",
    "with open(output_file, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Image Name\", \"Timestamp\", \"Extracted Text\"])\n",
    "    writer.writerow([image_name, timestamp, text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"output.csv\")\n",
    "\n",
    "# Specify the column containing the text\n",
    "text_column = \"Text\"\n",
    "\n",
    "# Specify the column containing the font type\n",
    "font_column = \"Font\"\n",
    "\n",
    "# Iterate over each row and extract the font type for each text entry\n",
    "for index, row in df.iterrows():\n",
    "    text = row[text_column]\n",
    "    font_type = row[font_column]\n",
    "    print(f\"Text: {text}, Font Type: {font_type}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Font dection github classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ocrd_typegroup_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install ocrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install virtualenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ocrd_typegroups_classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh test/test.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ocrd_typegroups_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrd_typegroups_classifier.typegroups_classifier import TypegroupsClassifier\n",
    "\n",
    "tgc = TypegroupsClassifier.load('ocrd_typegroups_classifier/models/densenet121.tgc')\n",
    "tgc.model.save_state_dict('model.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### font recognition classsifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.13.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.12.0)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.12.0-cp311-cp311-win_amd64.whl (272.9 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.13)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (67.7.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.56.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow-intel\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.13.0\n",
      "    Uninstalling tensorflow-estimator-2.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.13.1\n",
      "    Uninstalling keras-2.13.1:\n",
      "      Successfully uninstalled keras-2.13.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.13.0\n",
      "    Uninstalling tensorboard-2.13.0:\n",
      "      Successfully uninstalled tensorboard-2.13.0\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.13.0\n",
      "    Uninstalling tensorflow-intel-2.13.0:\n",
      "      Successfully uninstalled tensorflow-intel-2.13.0\n",
      "Successfully installed keras-2.12.0 tensorboard-2.12.3 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\lcss\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import ImageFilter\n",
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "import keras\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import os\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image(img_path):\n",
    "    pil_im =PIL.Image.open(img_path).convert('L')\n",
    "    pil_im=pil_im.resize((105,105))\n",
    "    #imshow(np.asarray(pil_im))\n",
    "    return pil_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_image(pil_im):\n",
    "    # Adding Noise to image\n",
    "    img_array = np.asarray(pil_im)\n",
    "    mean = 0.0   # some constant\n",
    "    std = 5   # some constant (standard deviation)\n",
    "    noisy_img = img_array + np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
    "    noise_img = PIL.Image.fromarray(np.uint8(noisy_img_clipped))\n",
    "    noise_img=noise_img.resize((105,105))\n",
    "    return noise_img\n",
    "def blur_image(pil_im):\n",
    "    #Adding Blur to image \n",
    "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3))\n",
    "    blur_img=blur_img.resize((105,105))\n",
    "    return blur_img\n",
    "def affine_rotation(img):\n",
    "    rows, columns = img.shape\n",
    "\n",
    "    point1 = np.float32([[10, 10], [30, 10], [10, 30]])\n",
    "    point2 = np.float32([[20, 15], [40, 10], [20, 40]])\n",
    "\n",
    "    A = cv2.getAffineTransform(point1, point2)\n",
    "\n",
    "    output = cv2.warpAffine(img, A, (columns, rows))\n",
    "    affine_img = PIL.Image.fromarray(np.uint8(output))\n",
    "    affine_img=affine_img.resize((105,105))\n",
    "    return affine_img\n",
    "def gradient_fill(image):\n",
    "    laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "    laplacian = cv2.resize(laplacian, (105, 105))\n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"font_patch/\" #Link to all samples created\n",
    "data=[]\n",
    "labels=[]\n",
    "imagePaths = sorted(list(paths.list_images(data_path)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "#These were the 5 fonts taken as sample\n",
    "def conv_label(label):\n",
    "    if label == 'Lato':\n",
    "        return 0\n",
    "    elif label == 'Raleway':\n",
    "        return 1\n",
    "    elif label == 'Roboto':\n",
    "        return 2\n",
    "    elif label == 'Sansation':\n",
    "        return 3\n",
    "    elif label == 'Walkway':\n",
    "        return 4\n",
    "augument=[\"blur\",\"noise\",\"affine\",\"gradient\"]\n",
    "a=itertools.combinations(augument, 4)\n",
    "\n",
    "for i in list(a): \n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    label = conv_label(label)\n",
    "    pil_img = pil_image(imagePath)\n",
    "    #imshow(pil_img)\n",
    "    \n",
    "    # Adding original image\n",
    "    org_img = img_to_array(pil_img)\n",
    "    #print(org_img.shape)\n",
    "    data.append(org_img)\n",
    "    labels.append(label)\n",
    "    \n",
    "    augument=[\"noise\",\"blur\",\"affine\",\"gradient\"]\n",
    "    for l in range(0,len(augument)):\n",
    "    \n",
    "        a=itertools.combinations(augument, l+1)\n",
    "\n",
    "        for i in list(a): \n",
    "            combinations=list(i)\n",
    "            print(len(combinations))\n",
    "            temp_img = pil_img\n",
    "            for j in combinations:\n",
    "            \n",
    "                if j == 'noise':\n",
    "                    # Adding Noise image\n",
    "                    temp_img = noise_image(temp_img)\n",
    "                    \n",
    "                elif j == 'blur':\n",
    "                    # Adding Blur image\n",
    "                    temp_img = blur_image(temp_img)\n",
    "                    #imshow(blur_img)\n",
    "                    \n",
    "    \n",
    "                elif j == 'affine':\n",
    "                    open_cv_affine = np.array(pil_img)\n",
    "                    # Adding affine rotation image\n",
    "                    temp_img = affine_rotation(open_cv_affine)\n",
    "\n",
    "                elif j == 'gradient':\n",
    "                    open_cv_gradient = np.array(pil_img)\n",
    "                    # Adding gradient image\n",
    "                    temp_img = gradient_fill(open_cv_gradient)\n",
    "  \n",
    "            temp_img = img_to_array(temp_img)\n",
    "            data.append(temp_img)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(data, dtype=\"float32\") / 255.0\n",
    "labels = np.array(labels, dtype=\"int\")\n",
    "print(\"Success\")\n",
    "\n",
    "if len(data) > 0:\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "    trainY = to_categorical(trainY, num_classes=5)\n",
    "    testY = to_categorical(testY, num_classes=5)\n",
    "\n",
    "    # Data augmentation\n",
    "    batch_size = 32\n",
    "    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                             shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "    augmented_data = aug.flow(trainX, trainY, batch_size=batch_size)\n",
    "else:\n",
    "    print(\"Insufficient data to perform the train-test split.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 58, 58, 64)        147520    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 58, 58, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 29, 29, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 128)         4718720   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 6, 6, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 6, 6, 128)        9437312   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 12, 12, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 24, 24, 64)       1179712   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 37, 256)       2359552   \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 256)       9437440   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 15, 15, 256)       9437440   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              235933696 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2383)              9763151   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 11920     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,208,543\n",
      "Trainable params: 299,208,159\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LCSS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    Conv2DTranspose,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.optimizers import legacy as keras_legacy_optimizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv Layers\n",
    "    model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(105, 105, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (24, 24), strides=(2, 2), activation='relu', padding='same', kernel_initializer='uniform'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (12, 12), strides=(2, 2), activation='relu', padding='same', kernel_initializer='uniform'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    # Conv Layers\n",
    "    model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2383, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Constants\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "# Create model\n",
    "model = create_model()\n",
    "\n",
    "# Optimizer and Compilation\n",
    "sgd = keras_legacy_optimizer.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "filepath = \"C:\\\\Users\\\\LCSS\\\\Desktop\\\\DS sip\\\\page0.jpg\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [early_stopping, checkpoint]\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Visualize model architecture\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Train the model\n",
    "# model.fit(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mfit(trainX, trainY,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      2\u001b[0m           batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      3\u001b[0m           epochs\u001b[39m=\u001b[39mepochs,\n\u001b[0;32m      4\u001b[0m           verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      5\u001b[0m           validation_data\u001b[39m=\u001b[39m(testX, testY),callbacks\u001b[39m=\u001b[39mcallbacks_list)\n\u001b[0;32m      6\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(testX, testY, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest loss:\u001b[39m\u001b[39m'\u001b[39m, score[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY,shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(testX, testY),callbacks=callbacks_list)\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"C:\\\\Users\\\\LCSS\\\\Desktop\\\\DS sip\\\\page0.jpg\")\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"sample/sample.jpg\"\n",
    "pil_im =PIL.Image.open(img_path).convert('L')\n",
    "pil_im=blur_image(pil_im)\n",
    "org_img = img_to_array(pil_im)\n",
    "def rev_conv_label(label):\n",
    "    if label == 0 :\n",
    "        return 'Lato'\n",
    "    elif label == 1:\n",
    "        return 'Raleway'\n",
    "    elif label == 2 :\n",
    "        return 'Roboto'\n",
    "    elif label == 3 :\n",
    "        return 'Sansation'\n",
    "    elif label == 4:\n",
    "        return 'Walkway'\n",
    "data=[]\n",
    "data.append(org_img)\n",
    "data = np.asarray(data, dtype=\"float\") / 255.0\n",
    "y = model.predict(data)\n",
    "y = np.round(y).astype(int)\n",
    "label = rev_conv_label(y[0,0])\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(pil_im, interpolation='nearest', cmap=cm.gray)\n",
    "ax.text(5, 5, label , bbox={'facecolor': 'white', 'pad': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
